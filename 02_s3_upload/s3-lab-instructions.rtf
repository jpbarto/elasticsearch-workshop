{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf200
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\csgray\c0;\csgray\c100000;}
\margl1440\margr1440\vieww16060\viewh19580\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\b\fs24 \cf0 Lab 2 \'93S3, Lambda, ElasticSearch\'94
\b0 \
\

\b 1 - Go to \'93Elastic Search\'94 in the AWS Console
\b0 \
\
Click on \'93Create a new domain\'94\
Type a domain name: i.e. \'93gslabs3\'94\
Select ElasticSearch version as \'932.3\'94\
Click \'93Next\'94\
Set Instance count as \'932\'94\
Set Instance type as \'93t2.medium.elastisearch\'94\
In the storage section set EBS Volume Size as \'9330\'94 GB and leave the rest of the options as default\
Click \'93Next\'94\
In the Network Configuration section, select Public Access\
In the Access Policy select the \'93Allow open access to the domain\'94 - !! WARNING !! This is not recommended for production\
Click Next, then\
Click Confirm to start the cluster creation\
\
(This can take up to 20 minutes, so please go to the next step)\
\

\b 2 - Go to S3 in the AWS Console
\b0 \
\
Click on \'93Create bucket\'94\
Enter a unique name for the bucket, i.e. gslabs3-$username\
Select region as \'93EU Ireland\'94\
Click on \'93Create\'94\
\

\b 3 - Go to Lambda in the AWS Console
\b0 \
\
Click on \'93Create function\'94\
Select \'93Author from scratch\'94\
Give your function a name, i.e. \'93imageIndexBuilder\'94\
Select Python 2.7 as the runtime\
Select \'93Create new role from template\'94\
Type a name for your role, i.e. \'93lambda_s3_read_access\'94\
In the Policy templates select \'93S3 object read-only permissions\'94\
Click on \'93Create function\'94\
\
Once complete, in the \'93Function code\'94 section, under \'93Code entry type\'94 click the drop-down menu and select \'91Upload a .ZIP file\'92\
(Browse to the GitHub repo and download code.zip to your computer)\
Select the code.zip file and then click save on the lambda function menu (top right)\
\
Once this is complete and you can see the code in the lambda_function code editor page, we have to enter your Elastic Search domain\'92s endpoint\
Find the line where we make a connection to the endpoint: esClient = connectES(\'93 **** \'93) and replace with your endpoint\
Save the function again.\
\
We will now enable S3 events to trigger this lambda function\
On the left, under \'93Add triggers\'94, click on S3\
On the \'93Configure triggers\'94 section:\
Under Bucket select the bucket you created earlier, i.e. \'93gslabs3-$username\'94\
Under Event type, select \'93Object Created (All)\'94\
Click Add on the bottom right to complete this step.\
\

\b At this point, we have configured ElasticSearch, S3, and Lambda.
\b0 \
\
Go back to S3 in the AWS Console.\
Click on the bucket you created earlier\
Upload your images\
\
Once finished, then you can query the ES index:\
\
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f1\fs22 \cf2 \cb3 \CocoaLigature0 curl -XGET https://search-gslab-3rkqcvlwngfjjvq4ldckzi3upm.eu-west-1.es.amazonaws.com/metadata-store/images/_search?pretty
\f0\fs24 \cf0 \cb1 \CocoaLigature1 \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0
\cf0 \
}